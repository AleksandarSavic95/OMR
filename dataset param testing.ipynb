{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "# iscrtavanje slika i plotova unutar samog browsera\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "# prikaz vecih slika \n",
    "pylab.rcParams['figure.figsize'] = 21,15\n",
    "\n",
    "import numpy as np\n",
    "import cv2 # OpenCV biblioteka\n",
    "\n",
    "def show_in_window_and_below(img, below=True):\n",
    "    if (below):\n",
    "        plt.imshow(img, 'gray')\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# current image extension\n",
    "ext = '.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# runs calculations\n",
    "def calculate_runs(img):\n",
    "    runs = [[1] for x in xrange(img.shape[1])] # each column starts with 1 black pixel\n",
    "    black_runs_flat, white_runs_flat = [], []\n",
    "    for col in xrange(img.shape[1]): # iterate through all columns\n",
    "        img[0,col] = 0 # PAINT THE FIRST PIXEL IN PREDEFINED COLOR, to make all columns start the same\n",
    "        run_index = 0 # start the run\n",
    "        for row in xrange(1, img.shape[0]): # for each pixel/row in current column\n",
    "            if (img[row-1 ,col] != img[row, col]):  # if they are not the same,\n",
    "                # memorize the old run in corresponding array\n",
    "                if (run_index % 2 == 0): # black run\n",
    "                    black_runs_flat.append(runs[col][run_index])\n",
    "                else:\n",
    "                    white_runs_flat.append(runs[col][run_index])\n",
    "                # start a new run\n",
    "                run_index += 1\n",
    "                runs[col].append(0)\n",
    "            runs[col][run_index] += 1     # add a pixel to the current run\n",
    "        # the column ended ==> save the last run for the ended column\n",
    "        if (run_index % 2 == 0): # black run\n",
    "            black_runs_flat.append(runs[col][run_index])\n",
    "        else:\n",
    "            white_runs_flat.append(runs[col][run_index])\n",
    "    return runs, black_runs_flat, white_runs_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# line thickness and spacings (black and white runs analysis)\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_line_thickness(black_flat):\n",
    "    num_top = 4\n",
    "    black_count = Counter(black_flat) # Counter({1: 3, 8: 1, 3: 1, ...})\n",
    "    m_c_black = black_count.most_common(num_top)\n",
    "    m_c_black1, m_c_black2 = m_c_black[0][0], m_c_black[1][0]\n",
    "    print 'Top', num_top, 'most common black runs:', m_c_black\n",
    "    if (m_c_black1*3 < m_c_black2): # kind of a sanity check\n",
    "        line_thickness = m_c_black1\n",
    "    else:\n",
    "        line_thickness = (m_c_black1 + m_c_black2) / 2.\n",
    "    print '>>> line thickness:  ', line_thickness\n",
    "    return line_thickness\n",
    "\n",
    "def calculate_line_spacing(white_flat, image_height):\n",
    "    num_top = 4\n",
    "    white_count = Counter(white_flat) # print white_count.most_common(50)\n",
    "    m_c_white = white_count.most_common(num_top)\n",
    "    m_c_white1, m_c_white2 = m_c_white[0][0], m_c_white[1][0]\n",
    "    print 'Top', num_top, 'most common white runs', m_c_white\n",
    "    \n",
    "    if (m_c_white1 > image_height*0.5): # sanity check\n",
    "        line_spacing = m_c_white2\n",
    "    else:\n",
    "        if (m_c_white2 > image_height*0.5):\n",
    "            line_spacing = m_c_white1\n",
    "        else:\n",
    "            line_spacing = (m_c_white1 + m_c_white2) / 2.\n",
    "    print 'line spacing: ', line_spacing\n",
    "    return line_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_staff_lines(img, runs, line_height, staff_thickness_multiplier):\n",
    "    # copy the image.. python is pass-by-object-reference so it is necessary!\n",
    "    p = img.copy() # pass-by-object-reference: https://stackoverflow.com/a/33066581/2101117\n",
    "    # NOTE: copying is NOT NECESSARY if we won't use the passed `img` after this function returns\n",
    "    #edit the image\n",
    "    for c in xrange(len(runs)):        # for every column\n",
    "        cumulative = 0 # initialize the number of passed pixels\n",
    "        for r in xrange(len(runs[c])): # for every run\n",
    "            run_length = runs[c][r]\n",
    "            if (r % 2 == 0): # black runs # every black run longer than 2 * line_height is deleted/whitened\n",
    "                if (run_length < line_height * staff_thickness_multiplier):\n",
    "                    # ++ AKO JE SLJEDEĆI/PRETHODNI %% BIJELI %% RUN = VISINA PRAZNINE +-1\n",
    "                    # ++ AKO JE SLJEDEĆI/PRETHODNI %%  CRNI  %% RUN = VISINA LINIJE +-1\n",
    "                    p[cumulative:cumulative + run_length, c] = [255]*(run_length)\n",
    "            #else: # white runs\n",
    "            #    do something maybe ?\n",
    "            cumulative += run_length\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# USE:\n",
    "#    = in lines-only image, to LOCATE the lines AND/OR check if there is a line on the current location/run\n",
    "#        - easier to find lines, since there are no other elements\n",
    "#        - takes more time, since we need to generate the lines-only image,\n",
    "#           ,BUT THAT IS NOT A PROBLEM SINCE WE WILL NEED IT TO LOCATE THE LINES\n",
    "#\n",
    "#    = in binary image, to check if there is a line on the current location/run\n",
    "#\n",
    "# da se utvrde linije treba samo odrediti visinu, a ne \n",
    "# TIP: mozda za svaki linijski sistem (ili cak liniju) cuvati vise x, koordinata,\n",
    "#   recimo na svaku petinu sirine slike provjeravati lokacije\n",
    "#   linijskih sistema (ili pojedinacnih linija) na vise mijesta u slici:\n",
    "#       |       |        |      |\n",
    "#       V       V        V      V\n",
    "# -----..____..--------------------  <== curved line, others are ok\n",
    "# --------------------------------- \n",
    "# ---------------------------------\n",
    "# ---------------------------------\n",
    "# ---------------------------------\n",
    "######\n",
    "# x je niz od onoliko crnih piksela koliko je prosjecna debljina linije (+-1 ili 2)\n",
    "# x = [0] * (int(thickness)-1)\n",
    "# y je niz od onoliko crnih piksela koliko je prosjecna debljina linije + 2 ili 3 ||| INT!\n",
    "#   ~ pikseli iz y niza pocinju od posljednje tacke posmatrane linije (tj.kandidata za liniju)\n",
    "# y = current_pos + int(spacing * 0.9 ili 0.8)\n",
    "# print x_in_y(x, y)\n",
    "###\n",
    "def x_in_y(x, y):\n",
    "    try:\n",
    "        x_len = len(x)\n",
    "    except TypeError:\n",
    "        x_len = 1\n",
    "        x = type(y)((x,))\n",
    "\n",
    "    for i in xrange(len(y)):\n",
    "        if (y[i : i+x_len] == x):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# a = [0,0,1,1,1,0,0,0,0]\n",
    "# b = [1,1,1]\n",
    "# b = 0 # works also\n",
    "# print x_in_y(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-2ea6a38f66a6>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-2ea6a38f66a6>\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    cumulative += run_length # !!!\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# ALG 2 - look at white runs around the line candidate\n",
    "# 2*d . . . 1*d . . . X . . . 1*d . . . 2*d\n",
    "#  0         1        -        2         3\n",
    "# In order for X to be whitened (erased):\n",
    "#\n",
    "\n",
    "def spacing_is_ok(run_length, line_spacing):\n",
    "#     print '>>> spacing_is_ok <<< run_length: {}, line_spacing: {}'.format(run_length, line_spacing)\n",
    "    return (run_length < (line_spacing * 1.15)) and (run_length > (line_spacing * 0.85))\n",
    "\n",
    "def run_has_lines_up_or_down(runs, current_index, line_thickness, line_spacing):\n",
    "    '''check if there is a line on `line_spacing` above or below the current index '''\n",
    "    lines = [255,255,255,255]\n",
    "    return 1\n",
    "\n",
    "def rm_staff_lines_up_down_neighbours(img, runs, line_thickness, line_spacing, staff_thickness_multiplier):\n",
    "    '''Removes staff lines by looking at every black run's neighbours, above and below.'''\n",
    "    # Original image is being changed + Python passes by obj-ref, so it's necessary\n",
    "    p = img.copy() # pass-by-object-reference: https://stackoverflow.com/a/33066581/2101117\n",
    "    # NOTE: copying is NOT NECESSARY if we won't use the passed `img` after this function returns\n",
    "    for c in xrange(len(runs)):        # for every column\n",
    "        cumulative = 0 # initialize the number of passed pixels\n",
    "        for r in xrange(len(runs[c])): # for every run\n",
    "            run_length = runs[c][r]\n",
    "            deleted = False # did we delete the run\n",
    "            if (r % 2 == 0): # check every black run, shorter than `thickness * multiplier`\n",
    "                if (run_length < line_thickness * staff_thickness_multiplier):\n",
    "                    # this is not the last run === check the run AFTER this one\n",
    "                    if (r + 1 < (len(runs[c]))):\n",
    "                        if spacing_is_ok(runs[c][r+1], line_spacing): # we found a line - delete it\n",
    "                            p[cumulative:cumulative + run_length, c] = [255]*(run_length)\n",
    "                            deleted = True\n",
    "                        # else: # more conditions to add.. like..\n",
    "                                # check if there is a black run above or below the current one,\n",
    "                                # on distance that is equal to line_spacing +-1,\n",
    "                                # whose lenght is = line_thickness +-1\n",
    "                            \n",
    "                    # this is not the first run === check the run BEFORE this one\n",
    "                    if (not deleted and (r - 1 >= 0)):\n",
    "                        if spacing_is_ok(runs[c][r-1], line_spacing): # we found a line - delete it\n",
    "                            p[cumulative:cumulative + run_length, c] = [255]*(run_length)\n",
    "                            deleted = True\n",
    "                    if (not deleted and run_has_lines_up_or_down()):\n",
    "                        \n",
    "            cumulative += run_length # !!!\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# ALG 3 - compare neighbour points on distance `d`,\n",
    "# to the left and right, from the observed point X:\n",
    "# 2*d . . . 1*d . . . X . . . 1*d . . . 2*d\n",
    "#  0         1        -        2         3\n",
    "# In order for X to be whitened (erased):\n",
    "#   - points[1] and points[2] should be black, or\n",
    "#   - points[0] and points[1] should be black, or\n",
    "#   - points[2] and points[3] should be black.\n",
    "\n",
    "def initialize_points(c, distance, img, compare_point, runs):\n",
    "    '''Gets the neighbours located '''\n",
    "    points = [255,255,255,255] # initially, pixels are white (maybe -1 if not accessible)\n",
    "    # 2*left , 1*left , 1*right, 2*right\n",
    "    if (c - distance >= 0): # we can get the 1*left pixel\n",
    "        points[1] = img[compare_point, c - distance]\n",
    "        if (c - 2*distance >= 0): # we can get the 2*left pixel\n",
    "            points[0] = img[compare_point, c - 2*distance]\n",
    "    if (c + distance < len(runs)): # we can get the right pixel\n",
    "        points[2] = img[compare_point, c + distance]\n",
    "        if (c + 2*distance < len(runs)):\n",
    "            points[3] = img[compare_point, c + 2*distance]\n",
    "    return points\n",
    "\n",
    "def rm_staff_lines_side_neighbours(img, runs, thickness, spacing, thickness_mul, distance):\n",
    "    if distance > len(runs)/2:\n",
    "        print 'WHOA! Distance is: {} and there are only {} columns'.format(distance, len(runs))\n",
    "        return img\n",
    "    int_thickness = int(thickness)+1\n",
    "    p = img.copy() # we will erase some lines, so copy the image\n",
    "    # NOTE: copying is NOT NECESSARY if we won't use the passed `img` after this function returns\n",
    "    for c in xrange(len(runs)): # for every column\n",
    "        cumulative = 0 # number of passed pixels\n",
    "        for r in xrange(len(runs[c])):\n",
    "            run_length = runs[c][r]\n",
    "            if (r % 2 == 0):# for every black run\n",
    "                if (run_length < thickness * thickness_mul):\n",
    "                    p[cumulative:cumulative + run_length, c] = [255]*(run_length)\n",
    "                    cumulative += run_length # !!!\n",
    "                    continue\n",
    "                else:\n",
    "                    pixels_to_remove = int_thickness\n",
    "                compare_point = cumulative + pixels_to_remove/2 # + run_length/2 # maybe later\n",
    "                # 4 values of neighbour pixels, some of them must be black,\n",
    "                #   for deletion of the observed pixel to happen.\n",
    "                points = initialize_points(c, distance, img, compare_point, runs)\n",
    "                if (points[1] == 0):\n",
    "                    if (points[2] == 0):\n",
    "                        p[cumulative: cumulative + pixels_to_remove, c] = [255]*pixels_to_remove\n",
    "                    else: # out of bounds or white # !! !!  ASSUMPTION !!  !!!\n",
    "                    # if (points[2] == -1): # more robust? Needs points=[-1,-1,-1,-1]\n",
    "                        # two to the left is black?\n",
    "                        if (points[0] == 0):\n",
    "                            p[cumulative: cumulative + pixels_to_remove, c] = [255]*pixels_to_remove\n",
    "                        # else: NIJE LINIJA :D\n",
    "                # no black point on the left\n",
    "                else:\n",
    "                    if (points[2] == 0 and points[3] == 0):\n",
    "                        p[cumulative: cumulative + pixels_to_remove, c] = [255]*pixels_to_remove\n",
    "            cumulative += run_length # !!!\n",
    "    # return the new, processed image\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_image(img, threshold_type, block_size, c_value, staff_thickness_multiplier, params=[]):\n",
    "    t_t, b_s, s_t_m = threshold_type, block_size, staff_thickness_multiplier\n",
    "    print('=========\\nthreshold_type: {}, block_size: {}, c_value: {}, staff_thickness_multiplier: {}'.format(t_t, b_s, c_value, s_t_m))\n",
    "    img_ada = cv2.adaptiveThreshold(img, 255, threshold_type, cv2.THRESH_BINARY, block_size, c_value)\n",
    "    \n",
    "    dilate_kernel = np.ones((1,30), dtype=np.int) # np.ones((kernel_w, kernel_h), dtype=np.int);\n",
    "    # staff lines LOCATIONS, along with lines-only image\n",
    "    lines_only_img, locations = cv2.dilate(img_ada, kernel, iterations=1)\n",
    "    \n",
    "    # runs calculation\n",
    "    runs, black_runs_flat, white_runs_flat = calculate_runs(img_ada)\n",
    "    line_thickness = calculate_line_thickness(black_runs_flat)\n",
    "    line_spacing = calculate_line_spacing(white_runs_flat, img_ada.shape[0]) # needs image height\n",
    "    result = rm_staff_lines_up_down_neighbours(img_ada, runs, line_thickness, line_spacing, staff_thickness_multiplier)\n",
    "#     distance = int(line_spacing * 0.5)\n",
    "#     result = rm_staff_lines_side_neighbours(img_ada, runs, line_thickness, line_spacing, staff_thickness_multiplier, distance)\n",
    "#     result = rm_s(img_ada, runs, line_thickness, line_spacing, staff_thickness_multiplier, distance)\n",
    "    \n",
    "    cv2.imwrite('./images/dataset/run_X/params_'+str(t_t)+'_'+str(b_s)+'_'+str(c_value)+'_'+str(s_t_m)+ext, result)\n",
    "    #cv2.imwrite('./images/dataset/run_Y/params_ORIGINAL.jpg', img_ada)\n",
    "\n",
    "img = cv2.imread('images/dataset/muzikanti'+ext, 0) #  0 -->  read as grayscale\n",
    "# parse_image(img, cv2.ADAPTIVE_THRESH_MEAN_C, 33, 35, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param values\n",
    "threshold_types = [cv2.ADAPTIVE_THRESH_MEAN_C]# , cv2.ADAPTIVE_THRESH_GAUSSIAN_C # const values are 0 and 1\n",
    "block_sizes = [33,35,37,39,43]# [11, 19, 27, 35, 43] # [11,15,19,23,27,31,35, 39, 43]\n",
    "c_values = [29,33,35,37] # [17,19,21] # [11, 19, 27, 35, 43] # [11,15,19,23,27,31,35, 39, 43]\n",
    "staff_thickness_multipliers = [1.3, 1.5] # [1., 1.5, 2., 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 29, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(4, 36510), (3, 33167)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24794), (20, 15403)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 29, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(4, 36510), (3, 33167)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24794), (20, 15403)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 33, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 38242), (4, 31349)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26952), (20, 12360)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 33, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 38242), (4, 31349)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26952), (20, 12360)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 35, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 40454), (4, 28812)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27762), (20, 10863)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 35, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 40454), (4, 28812)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27762), (20, 10863)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 37, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 42531), (4, 26346)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28398), (22, 9849)]\n",
      "space height:  21.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 33, c_value: 37, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 42531), (4, 26346)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28398), (22, 9849)]\n",
      "space height:  21.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 29, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(4, 36929), (3, 32689)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24611), (20, 15681)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 29, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(4, 36929), (3, 32689)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24611), (20, 15681)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 33, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 37631), (4, 31899)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26735), (20, 12688)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 33, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 37631), (4, 31899)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26735), (20, 12688)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 35, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 40005), (4, 29334)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27639), (20, 11178)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 35, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 40005), (4, 29334)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27639), (20, 11178)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 37, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 42045), (4, 26869)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28296), (22, 9763)]\n",
      "space height:  21.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 35, c_value: 37, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 42045), (4, 26869)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28296), (22, 9763)]\n",
      "space height:  21.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 29, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(4, 37275), (3, 32232)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24398), (20, 15945)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 29, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(4, 37275), (3, 32232)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24398), (20, 15945)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 33, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 37110), (4, 32385)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26538), (20, 12949)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 33, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 37110), (4, 32385)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26538), (20, 12949)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 35, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 39532), (4, 29812)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27464), (20, 11463)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 35, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 39532), (4, 29812)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27464), (20, 11463)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 37, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 41642), (4, 27315)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28181), (20, 10022)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 37, c_value: 37, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 41642), (4, 27315)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28181), (20, 10022)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 29, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(4, 37697), (3, 31755)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24236), (20, 16220)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 29, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(4, 37697), (3, 31755)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 24236), (20, 16220)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 33, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 36692), (4, 32808)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26424), (20, 13212)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 33, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 36692), (4, 32808)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 26424), (20, 13212)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 35, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 39108), (4, 30247)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27329), (20, 11717)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 35, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 39108), (4, 30247)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27329), (20, 11717)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 37, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 41251), (4, 27770)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28074), (20, 10289)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 39, c_value: 37, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 41251), (4, 27770)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28074), (20, 10289)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 29, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(4, 36534), (3, 32881)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 25559), (20, 15173)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 29, staff_thickness_multiplier: 1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two most common black runs: [(4, 36534), (3, 32881)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 25559), (20, 15173)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 33, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 37651), (4, 31786)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27641), (20, 12117)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 33, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 37651), (4, 31786)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 27641), (20, 12117)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 35, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 39893), (4, 29339)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28482), (20, 10654)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 35, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 39893), (4, 29339)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 28482), (20, 10654)]\n",
      "space height:  20.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 37, staff_thickness_multiplier: 1.3\n",
      "Top two most common black runs: [(3, 41990), (4, 26880)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 29094), (22, 9839)]\n",
      "space height:  21.5\n",
      "=========\n",
      "threshold_type: 0, block_size: 43, c_value: 37, staff_thickness_multiplier: 1.5\n",
      "Top two most common black runs: [(3, 41990), (4, 26880)]\n",
      ">>> line height:   3.5\n",
      "Top two most common white runs [(21, 29094), (22, 9839)]\n",
      "space height:  21.5\n"
     ]
    }
   ],
   "source": [
    "for thresh_type in threshold_types:\n",
    "    for block_size in block_sizes:\n",
    "        for c_val in c_values:\n",
    "            for s_t_mul in staff_thickness_multipliers:\n",
    "                parse_image(img, thresh_type, block_size, c_val, s_t_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEKS:  0\n",
      "\tLINIJA\n",
      "INDEKS:  2\n",
      "\tLINIJA\n",
      "INDEKS:  4\n",
      "INDEKS:  6\n",
      "\tLINIJA\n",
      "INDEKS:  8\n",
      "\tLINIJA\n"
     ]
    }
   ],
   "source": [
    "praznina = 20\n",
    "# ln - linija  || pr - praznina || C- crno-ne-linija || B- bijelo-ne-praznina\n",
    "#     ln1,pr1,ln2,pr2,C,pr2,ln3,pr3\n",
    "col_runs = [4, 20, 4, 10, 3, 7, 4, 21, 4, 21] # run-ovi u jednoj koloni\n",
    "index = 4 # sad smo kod spornog crnog run-a\n",
    "# prethodni bijeli run sirok kao praznina AND razlika izmedju \n",
    "is_line = False\n",
    "for i in range(0, len(col_runs), 2):\n",
    "    print 'INDEKS: ', i\n",
    "    # nije posljednji run === gledamo naredni run\n",
    "    if (i < len(col_runs) - 1):\n",
    "        run_after = col_runs[i+1]\n",
    "        if (run_after < praznina * 1.15) and (run_after > praznina * 0.85):\n",
    "            print '\\tLINIJA'\n",
    "            continue # nema potrebe da provjeravamo prazninu iznad\n",
    "    # nije prvi run === gledamo prehodni run\n",
    "    if (i > 0):\n",
    "        run_before = col_runs[i-1]\n",
    "        if (run_before < praznina * 1.15) and (run_before > praznina* 0.85): #abs(col_runs[index-1] - praznina) < praznina * 0.1)\n",
    "            print '\\tLINIJA'\n",
    "\n",
    "# index = 8 # ovo je stvarno linija\n",
    "# 20*0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_w, kernel_h = 1, 30\n",
    "kernel_w, kernel_h = 30, 1\n",
    "kernel_w, kernel_h = 15, 3\n",
    "kernel_w, kernel_h = 10, 10\n",
    "kernel_w, kernel_h = 5, 5\n",
    "kernel_w, kernel_h = 3, 3\n",
    "kernel = np.ones((kernel_w, kernel_h), dtype=np.int);\n",
    "\n",
    "# kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "# print 'kernel', kernel\n",
    "\n",
    "img_edited1 = cv2.imread('./images/dataset/params_0_33_35_1.5.JPG')\n",
    "img_edited2 = cv2.imread('./images/dataset/params_0_35_19_1.5.JPG')\n",
    "\n",
    "dilated1 = cv2.dilate(img_edited1, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/dilated_33_35_kernel_{}_{}.jpg'.format(kernel_w, kernel_h), dilated1)\n",
    "dilated2 = cv2.dilate(img_edited2, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/dilated_35_19_kernel_{}_{}.jpg'.format(kernel_w, kernel_h), dilated2)\n",
    "\n",
    "eroded1 = cv2.erode(dilated1, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/er_dil_35_19_kernel_{}_{}.jpg'.format(kernel_w, kernel_h), eroded1)\n",
    "\n",
    "eroded2 = cv2.erode(dilated2, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/er_dil_33_35_kernel_{}_{}.jpg'.format(kernel_w, kernel_h), eroded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_w, kernel_h = 10,10\n",
    "dil = cv2.dilate(img_edited2, kernel, iterations=1)\n",
    "er = cv2.erode(dil, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/er_dil_w5_h2.jpg', er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_w, kernel_h = 10,10\n",
    "er = cv2.erode(img_edited2, kernel, iterations=1)\n",
    "dil = cv2.dilate(er, kernel, iterations=1)\n",
    "cv2.imwrite('./images/dataset/dil_er_w{}_h{}.jpg'.format(kernel_w, kernel_h), dil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test various kernel dimensions on  binarized images with\n",
    "# morph. operations: erosion, dilation, opening  and  closing\n",
    "kernel_widths = [2, 3, 5, 7]\n",
    "kernel_heights = [2, 3, 5, 7]\n",
    "\n",
    "block_sizes = [51, 51]\n",
    "c_values = [35, 45]\n",
    "for i in range(2):\n",
    "    img_path = './images/adaptive_params_testing/t_0_b_{}_c_{}.jpg'.format(block_sizes[i], c_values[i])\n",
    "    img = cv2.imread(img_path, 0) # grayscale! (actually binarized, but format is the same)\n",
    "    for kernel_width in kernel_widths:\n",
    "        for kernel_height in kernel_heights:\n",
    "            kernel = np.ones((kernel_width, kernel_height), dtype=np.int)\n",
    "            eroded = cv2.erode(img, kernel, iterations=1)\n",
    "            dilated = cv2.dilate(img, kernel, iterations=1)\n",
    "            er_b4_dil = cv2.dilate(er, kernel, iterations=1)\n",
    "            dil_b4_er = cv2.erode(dil, kernel, iterations=1)\n",
    "            \n",
    "            cv2.imwrite('./images/kernel_2/ER_b_{}_c_{}_kw_{}_kh_{}.jpg'\\\n",
    "                        .format(block_sizes[i], c_values[i], kernel_width, kernel_height),  eroded)\n",
    "            cv2.imwrite('./images/kernel_2/DIL_b_{}_c_{}_kw_{}_kh_{}.jpg'\\\n",
    "                        .format(block_sizes[i], c_values[i], kernel_width, kernel_height),  dilated)\n",
    "            cv2.imwrite('./images/kernel_2/ER_B4_DIL_b_{}_c_{}_kw_{}_kh_{}.jpg'\\\n",
    "                        .format(block_sizes[i], c_values[i], kernel_width, kernel_height),  er_b4_dil)\n",
    "            cv2.imwrite('./images/kernel_2/DIL_B4_ER_b_{}_c_{}_kw_{}_kh_{}.jpg'\\\n",
    "                        .format(block_sizes[i], c_values[i], kernel_width, kernel_height),  dil_b4_er)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 most common black runs: [(3, 44701), (4, 22766), (2, 6691), (1, 3474)]\n",
      ">>> line thickness:   3.5\n",
      "Top 4 most common white runs [(21, 29309), (22, 11747), (20, 6365), (23, 3600)]\n",
      "line spacing:  21.5\n"
     ]
    }
   ],
   "source": [
    "block_sizes = [51]#, 51] #  ]#\n",
    "c_values = [35]#, 45]    #  ]#\n",
    "thresh = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "method = cv2.THRESH_BINARY\n",
    "img = cv2.imread('images/dataset/muzikanti'+ext, 0) #  0 => read as grayscale\n",
    "\n",
    "for i in range(len(block_sizes)):\n",
    "    block = block_sizes[i]\n",
    "    c = c_values[i]\n",
    "    img = cv2.adaptiveThreshold(img, 255, thresh, method, block, c)\n",
    "    \n",
    "    k_w = 3\n",
    "    k_h = 1\n",
    "    kernel = np.ones((k_w, k_h), dtype=np.int)\n",
    "#     img_er = cv2.erode(img, kernel)\n",
    "#     cv2.imwrite('./images/e/51_31_k{}_{}.jpg'.format(k_w, k_h), img_er)\n",
    "    \n",
    "#     img = img_er # !!! # da ne mijenjam svuda\n",
    "    \n",
    "    # img.shape # [ VISINA, SIRINA ]\n",
    "    \n",
    "    runs, black_runs_flat, white_runs_flat = calculate_runs(img) # runs calculation, for thickness and spacing\n",
    "    line_thickness = calculate_line_thickness(black_runs_flat)\n",
    "    line_spacing = calculate_line_spacing(white_runs_flat, img.shape[0]) # needs image height\n",
    "    \n",
    "    thickness_mul = 1.5 # staff_thickness_multiplier\n",
    "    \n",
    "#     rm_s_l = remove_staff_lines(img, runs, line_thickness, thickness_mul)\n",
    "#     path_regular = './images/e/k{}_{}_b_{}_c_{}_RM_S_L.jpg'\n",
    "#     cv2.imwrite(path_regular.format(k_w, k_h, block, c), rm_s_l)\n",
    "    \n",
    "    rm_s_l_up_down = rm_staff_lines_up_down_neighbours(img, runs, line_thickness, line_spacing, thickness_mul)\n",
    "    path_up_down = './images/e/b_{}_c_{}_RM_S_L_UP_DOWN.jpg'\n",
    "    cv2.imwrite(path_up_down.format(block, c), rm_s_l_up_down)\n",
    "    \n",
    "    path_up_down_dil = './images/e/DIL_3_1_x2_b_{}_c_{}_RM_S_L_UP_DOWN.jpg'\n",
    "    up_down_dilated = cv2.dilate(rm_s_l_up_down, kernel)\n",
    "    cv2.imwrite(path_up_down_dil.format(block, c), up_down_dilated)\n",
    "    \n",
    "    k_w = 5 # above kernel is 5 1. This is 5 2\n",
    "    k_h = 2\n",
    "    kernel = np.ones((k_w, k_h), dtype=np.int)\n",
    "    path_up_down_dil = './images/e/DIL_5_2_b_{}_c_{}_RM_S_L_UP_DOWN.jpg'\n",
    "    up_down_dilated = cv2.dilate(rm_s_l_up_down, kernel)\n",
    "    cv2.imwrite(path_up_down_dil.format(block, c), up_down_dilated)\n",
    "    \n",
    "#     distance = int(line_spacing * 0.5) ### check for: * 1, * 1.3, * 1.5\n",
    "#     rm_s_l_side = rm_staff_lines_side_neighbours(img, runs, line_thickness, line_spacing, thickness_mul, distance)\n",
    "#     path_side = './images/e/b_{}_c_{}_RM_S_L_SIDE.jpg'\n",
    "#     cv2.imwrite(path_side.format(block, c), rm_s_l_side)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_and_save(img, kernel_w, kernel_h):\n",
    "    '''Dilates a binary image with kernel of specified dimensions.\n",
    "    saves the image to hard drive and returns the saved image'''\n",
    "    kernel = np.ones((kernel_w, kernel_h), dtype=np.int)\n",
    "    lines_only_img = cv2.dilate(img, kernel, iterations=1)\n",
    "    lines_only_img_path = './images/locate_lines/dil_{}_{}.jpg'.format(kernel_w, kernel_h)\n",
    "    cv2.imwrite(lines_only_img_path, lines_only_img)\n",
    "    return lines_only_img\n",
    "\n",
    "def erode_and_save(img, kernel_w_e, kernel_h_e, kernel_w_d=0, kernel_h_d=0):\n",
    "    '''Erodes a binary image with kernel of specified dimensions.\n",
    "    saves the image to hard drive and returns the saved image'''\n",
    "    if (kernel_w_d == 0):\n",
    "        dil_str = ''\n",
    "    else:\n",
    "        dil_str = '_dil_{}_{}'.format(kernel_w_d, kernel_h_d)\n",
    "    \n",
    "    kernel = np.ones((kernel_w_e, kernel_h_e), dtype=np.int)\n",
    "    lines_only_img = cv2.erode(img, kernel, iterations=1)\n",
    "    lines_only_img_path = './images/locate_lines/er_{}_{}{}.jpg'.format(kernel_w_e, kernel_h_e, dil_str)\n",
    "    cv2.imwrite(lines_only_img_path, lines_only_img)\n",
    "    return lines_only_img\n",
    "\n",
    "def locate_lines(img):\n",
    "    '''Locate lines.\n",
    "    Returns: staff lines LOCATIONS and the lines-only image'''\n",
    "    threshold = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    method, block, c = cv2.THRESH_BINARY, 55, 9\n",
    "    img_ada = cv2.adaptiveThreshold(img, 255, threshold, method, block, c)\n",
    "\n",
    "    # dilate with 1x50 --> erode with 2x50 \n",
    "    kernel_w, kernel_h = 1, 50\n",
    "    dilated = dilate_and_save(img_ada, kernel_w, kernel_h)\n",
    "    kernel_w_e, kernel_h_e = 2, 50\n",
    "    erode_the_dilated = erode_and_save(dilated, kernel_w, kernel_h)\n",
    "#     erode_the_dilated = erode_and_save(dilated, kernel_w_e, kernel_h_e, kernel_w, kernel_h )\n",
    "#     line locations = locate_lines # CONTINUE FROM TXT FILE !!!\n",
    "#     line locations = locate_lines # CONTINUE FROM TXT FILE !!!\n",
    "#     line locations = locate_lines # CONTINUE FROM TXT FILE !!!\n",
    "    \n",
    "img = cv2.imread('./images/dataset/muzikanti.JPG', 0) # 0 --> read as grayscale\n",
    "locate_lines(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
